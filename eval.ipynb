{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-01 23:52:55.230955: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-01 23:52:55.271504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740844375.287620    1410 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740844375.291528    1410 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-01 23:52:55.347619: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import os\n",
    "import json\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "# 设置可见GPU设备（根据实际GPU情况调整）\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 指定仅使用GPU \n",
    "\n",
    "# 路径配置 ------------------------------------------------------------------------\n",
    "base_model_path = \"/home/jzyoung/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B\" # 原始预训练模型路径\n",
    "peft_model_path = \"./output/\" # LoRA微调后保存的适配器路径\n",
    "bert_model_path=\"/home/jzyoung/.cache/modelscope/hub/models/tiansz/bert-base-chinese\"\n",
    "\n",
    "# 模型加载 ------------------------------------------------------------------------\n",
    "# 初始化分词器（使用与训练时相同的tokenizer）\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# 加载基础模型（半精度加载节省显存）\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "  base_model_path,\n",
    "  torch_dtype=torch.float16, # 使用float16精度\n",
    "  device_map=\"auto\"      # 自动分配设备（CPU/GPU）\n",
    ")\n",
    "\n",
    "# 加载LoRA适配器（在基础模型上加载微调参数）\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "  base_model, \n",
    "  peft_model_path,\n",
    "  torch_dtype=torch.float16,\n",
    "  device_map=\"auto\"\n",
    ")\n",
    "# 合并LoRA权重到基础模型（提升推理速度，但会失去再次训练的能力）\n",
    "lora_model = lora_model.merge_and_unload() \n",
    "lora_model.eval() # 设置为评估模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 生成函数 ------------------------------------------------------------------------\n",
    "def generate_response(model, prompt):\n",
    "  \"\"\"统一的生成函数\n",
    "  参数：\n",
    "    model : 要使用的模型实例\n",
    "    prompt : 符合格式要求的输入文本\n",
    "  返回：\n",
    "    清洗后的回答文本\n",
    "  \"\"\"\n",
    "  # 输入编码（保持与训练时相同的处理方式）\n",
    "  inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",     # 返回PyTorch张量\n",
    "    max_length=1024,        # 最大输入长度（与训练时一致）\n",
    "    truncation=True,       # 启用截断\n",
    "    padding=\"max_length\"     # 填充到最大长度（保证batch一致性）\n",
    "  ).to(model.device)        # 确保输入与模型在同一设备\n",
    "\n",
    "  # 文本生成（关闭梯度计算以节省内存）\n",
    "  with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "      input_ids=inputs.input_ids,\n",
    "      attention_mask=inputs.attention_mask,\n",
    "      max_new_tokens=1024,    # 生成内容的最大token数（控制回答长度）\n",
    "      temperature=0.7,     # 温度参数（0.0-1.0，值越大随机性越强）\n",
    "      top_p=0.9,        # 核采样参数（保留累积概率前90%的token）\n",
    "      repetition_penalty=1.1, # 重复惩罚系数（>1.0时抑制重复内容）\n",
    "      eos_token_id=tokenizer.eos_token_id, # 结束符ID\n",
    "      pad_token_id=tokenizer.pad_token_id, # 填充符ID \n",
    "    )\n",
    "  \n",
    "  # 解码与清洗输出\n",
    "  full_text = tokenizer.decode(outputs[0], skip_special_tokens=True) # 跳过特殊token\n",
    "  answer = full_text.split(\"### 答案：\\n\")[-1].strip() # 提取答案部分\n",
    "  return answer\n",
    "\n",
    "# 对比测试函数 --------------------------------------------------------------------\n",
    "def compare_models(question):\n",
    "  \"\"\"模型对比函数\n",
    "  参数：\n",
    "    question : 自然语言形式的医疗问题\n",
    "  \"\"\"\n",
    "  # 构建符合训练格式的prompt（注意与训练时格式完全一致）\n",
    "  prompt = f\"诊断问题：{question}\\n详细分析：\\n### 答案：\\n\"\n",
    "  \n",
    "  # 双模型生成\n",
    "  base_answer = generate_response(base_model, prompt) # 原始模型\n",
    "  lora_answer = generate_response(lora_model, prompt) # 微调模型\n",
    "  \n",
    "  # 终端彩色打印对比结果\n",
    "  print(\"\\n\" + \"=\"*50) # 分隔线\n",
    "  print(f\"问题：{question}\")\n",
    "  print(\"-\"*50)\n",
    "  print(f\"\\033[1;34m[原始模型]\\033[0m\\n{base_answer}\") # 蓝色显示原始模型结果\n",
    "  print(\"-\"*50)\n",
    "  print(f\"\\033[1;32m[LoRA模型]\\033[0m\\n{lora_answer}\") # 绿色显示微调模型结果\n",
    "  print(\"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file:  [{'Question': '根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？', 'Complex_CoT': '这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\\n\\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\\n\\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\\n\\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\\n\\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\\n\\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\\n\\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\\n\\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\\n\\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\\n\\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。', 'Response': '从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。'}, {'Question': '对于一名60岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，请问哪一项实验室检查对了解胸水的性质更有帮助？', 'Complex_CoT': \"嗯，有一个60岁的男性患者，出现了右侧胸疼，而且X光显示右侧肋膈角消失，这看起来很像是胸腔积液的问题。医生诊断是肺结核伴右侧胸腔积液。那我们就得想想，什么样的实验室检查能帮助我们更好地理解这个胸水的性质呢？\\n\\n首先，我们得从基础知识说起。胸腔积液就是说胸腔里有了多余的液体。这液体的来源可能是感染、恶性肿瘤或者其他因素。病因有些复杂，所以了解胸水性质很关键。\\n\\n嗯，实验室检查一般是用来分析胸水的，看看它到底是从哪儿来的。常见的检测项包括蛋白质、乳酸脱氢酶（LDH）、葡萄糖，以及更具体的病原检测，比如结核菌。\\n\\n患者是肺结核，那我们就要考虑到这可能是结核性胸腔积液。先要判断胸水的类型：是漏出液还是渗出液呢？为了确定这个，我们通常会用Light's标准，这个标准可以通过胸水的蛋白浓度和LDH水平区分。\\n\\n但是吧，光知道是渗出液可能还不足以确认是不是结核引起的。这时，结核相关的精确检测就显得格外重要，比如说结核菌PCR或者ADA（腺苷脱氨酶）活性。\\n\\n对了，ADA这个指标很有意思，特别是在结核性胸腔积液中。当ADA活性高的时候，通常会提示我们大概率是结核病。因此，虽然蛋白质和LDH很重要，但要确认结核，ADA或许更直接些。\\n\\n也就是说，虽然最开始我们要确认胸水是渗出液，但结合患者肺结核的情况，ADA检测会给我们更好的线索。\\n\\n所以，经过这么一番思考，我觉得对于已经被诊断为肺结核的患者来说，检测腺苷脱氨酶（ADA）更有指引性。这能帮忙进一步确认胸水与结核感染的关联。\\n\\n嗯，综上所述，ADA作为分析结核性胸腔积液的指标真的非常有效，最终还是选择它来作进一步检查。\", 'Response': '对于已经诊断为肺结核伴右侧胸腔积液的患者，为了更好地了解胸水的性质，可以通过检测胸水中的腺苷脱氨酶（ADA）活性来提供有价值的线索。ADA活性高通常提示结核性胸腔积液的可能性更大，因此在这种情况下，ADA检测相较于其他指标如蛋白质和乳酸脱氢酶（LDH）而言，更具诊断意义。'}]\n",
      "Generating reponses of base model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:19<00:00, 10.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating reponses of lora sft model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:56<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"./dataset/medical_o1_sft_Chinese.json\") as f:\n",
    "    test_data = json.load(f) \n",
    "    print(\"load file: \", test_data[:2])\n",
    "\n",
    "# 数据量比较大，我们只选择10条数据进行测试\n",
    "test_data=test_data[:30]\n",
    "# 批量生成回答\n",
    "\n",
    "def batch_generate(model, questions):\n",
    "    answers = []\n",
    "    for q in tqdm(questions):\n",
    "        prompt = f\"诊断问题：{q}\\n详细分析：\\n### 答案：\\n\"\n",
    "        ans = generate_response(model, prompt)\n",
    "        answers.append(ans)\n",
    "    return answers\n",
    "\n",
    "# 生成结果\n",
    "print(\"Generating reponses of base model ...\")\n",
    "base_answers = batch_generate(base_model, [d[\"Question\"] for d in test_data])\n",
    "print(\"Generating reponses of lora sft model ...\")\n",
    "lora_answers = batch_generate(lora_model, [d[\"Question\"] for d in test_data])\n",
    "ref_answers = [d[\"Response\"] for d in test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base answer: \n",
      " ['这个1岁的小孩在夏天头皮上出现了许多小结节，而且这些症状一直都没有好转，看起来有点麻烦。不过我们还得关注到，现在这些结节已经长得蛮大，像是有了 bigger 大大的感染，流出来的脓也不少。此外，小孩的嘴巴没有闭合的时候，头皮下面也会看到一些空洞。这让我想到，可能和头皮上的感染有关。\\n\\n再仔细想想，小孩在夏天头皮上的症状，尤其是在夏天，可能和湿热有关。在中医看来，夏天很常见湿热的问题，但这里又提到这些结节不像简单的热伤，因为它们已经变大并且脓流得厉害，这就有些不同了。\\n\\n再看看其他症状，比如头皮上的空洞、皮肤增厚，这些地方都是有可能是感染的迹象。如果结合这些，再加上夏天的气候环境，我开始觉得可能是湿热性皮炎，也就是所谓的“夏毒”皮炎。这种病在中医里常常与湿热相关联，特别是在儿童中，这种情况也不少见。\\n\\n所以，综合来看，这些症状符合“夏毒”皮炎的特点，我觉得这个诊断应该是比较合理的。再结合一些临床经验，好像也能解释为什么这些小结节会越来越大，以及脓液不断往外流。\\n### 答案：根据您的描述，这位1岁孩子的头皮症状，包括多处小结节、 AACW（脓破溃）、口不收敛以及头皮下空洞等，确实提示可能存在某种感染。在中医的视角，这种情况与湿热性皮炎（即“夏毒”皮炎）非常相符。\\n\\n湿热性皮炎通常与体表湿热有关，尤其是夏天，湿热外侵至内脏时，可能会引起类似的症状表现。具体来说：\\n\\n1. **小结节**：由于湿热侵袭，头皮表面出现结节，这是身体对湿热的一种 outward response。\\n\\n2. ** AACW（脓破溃）**：当湿热加剧时，体内可能积聚更多的脓液，形成渗出或渗漏状的结构。\\n\\n3. **头皮增厚及空洞**：这些可能是皮肤的炎症反应和局部缺损的表现。\\n\\n因此，在中医的诊断中，这些症状可被评估为湿热性皮炎。在实际治疗中，应结合传统的中药疗法，例如清热解毒、祛湿消肿等，以缓解症状。同时，密切监测病情变化也是至关重要的。<|endoftext|>', '在考虑一个60岁的男性患者的情况下，他出现了右侧胸痛，并且X线检查显示右侧肋膈角消失。医生诊断是肺结核伴随右侧胸腔积液。现在我们需要搞清楚胸水的性质是什么。\\n\\n首先，胸水可能有两种主要类型：一种是液体，另一种是粘连性液体，也就是那些看起来像是胶原蛋白的东西。\\n\\n要弄清楚哪种类型的胸水存在，我们得做些进一步的检查。通常情况下，胸水性质的检测是一个关键步骤。\\n\\n我听说血液学检查是个不错的选择。特别是用血清白细胞计数来判断是不是感染引起的。如果白细胞数目增加，那就很可能是感染导致的。\\n\\n不过，等等，也许还有其他可能性。虽然血液学检查很有价值，但如果我们知道胸水是由什么构成的呢？这就需要看看有没有别的办法确认一下。\\n\\n哦，对了，CT或者MRI可以帮到我们很多。它们可以帮助我们看到胸水中液体的具体情况，是不是像粘连性的？\\n\\n但是等等，我们不能只凭影像学检查就下结论。即使有CT或MRI的结果，我们还得去核实白细胞变化，毕竟感染性胸膜炎的可能性不容忽视。\\n\\n所以，总的来说，在这种情况下，虽然血液学中的白细胞检验非常有用，但它可能不能完全告诉我们胸水到底是哪种类型的。\\n\\n最终，我觉得还是先做个胸片检查可能会比较合适。因为通过胸片我们可以直接看到胸水是在哪里，是粘连性的还是其他形式的。\\n\\n总之，综合来看，胸片会给我们关于胸水性质的重要信息，这应该是目前最合适的检查方法。\\n### 答案：在面对这种情况时，我们应该仔细考虑如何获取有关胸水性质的明确信息。尽管血液学检查如白细胞计数异常在确诊感染性胸膜炎方面有重要作用，但在已经确诊为肺结核伴右侧胸腔积液的情况下，胸片检查有助于更直观地了解胸水的构成和性质。\\n\\n胸片可以通过观察胸腔内是否有积液形成以及其形态特征来提供重要线索。如果胸水包含粘连性成分，通常表现为透明、无颗粒感，并且在拍片时，水滴常常与胸膜壁接触并形成可见边界。相比之下，如果是非粘连性的胸水，则通常表现为-gray染色，水滴不会与胸膜壁发生界限。\\n\\n因此，在已知胸水由液体构成的情况下，胸片能够帮助我们识别胸水是粘连性的还是非粘连性的。虽然上述推理基于一般标准的临床诊断流程，但具体诊断仍需结合临床经验及专业评估以获得准确结果。<|endoftext|>']\n",
      "lora answer: \n",
      " ['这个1岁的小孩在夏天头皮上出现了许多小结节，而且这些结节一直没好，现在看起来已经相当严重了。这让我想到，夏天湿热气候的环境可能让他接触到了一些湿热的东西。\\n\\n哦，他说皮肤还有哪里增厚，这种情况很常见，尤其是在湿热引起的感染或炎症早期。再加上这些结节不能愈合，很可能和某种慢性感染有关。\\n\\n然后我发现，头皮下的地方也有很多空洞。这让我觉得可能有点更复杂，因为不是每个地方都一样，甚至可能和皮肤本身的问题有关。\\n\\n说到中医，我首先想到了风热伤表的情况。夏天确实是典型的湿热和热毒影响到身体表层的时候，而这些表层损伤就会导致类似结节这样的表现。\\n\\n可是再想想，这种以皮肤为标志的症状似乎不太够全面，因为多处小结节和非 convergent 的口部伤损常常提示着更复杂的炎症过程。\\n\\n如果是慢性炎症的话，风热伤表也许不完全解释得通，因为主要症状更多是长期未愈合的表浅损伤，并不是表表之间的明显区别。\\n\\n所以，我觉得，除了风热外，可能还有其他因素在起作用，比如表证或者寒证之类的。尤其是这个“增厚”症状，可能是由于皮肤的表证发展了。\\n\\n最后，综合考虑，虽然一开始想的是风热伤表，但因为其他症状的存在，我也必须承认，还需要排除其他的可能性。\\n\\n这样想来，头皮上的这些表证症状，可能还涉及到表证与寒证的结合，毕竟这些症状混杂在一起往往暗示着更广泛的表证进展，包括更严重的表证。\\n\\n因此，最终看来，这个孩子的症状，在中医上应该看作表证，而不是单纯的风热伤表。看来之前的判断需要修正。\\n### 答案：从中医的角度来看，这名1岁孩子在夏季出现的多处小结节、长期不愈合的症状，以及当前的溃破流脓情况，非常符合表证的表现。特别是在夏季湿热的环境中，表证是很常见的原因。以下是对此病症的具体分析：\\n\\n1. **风热伤表**是一种常见的表证表现，其中风热侵入表层组织造成表浅损伤。然而，题目中提到的“多处小结节”和“口不收敛”的症状，更倾向于表证较重的情况，而不仅仅是风热伤表。\\n\\n2. **表证**在中医中指由于外邪侵袭、伤及内脏表层组织所导致的疾病表现。此患儿的症状，例如多处结节、皮肤增厚等，都是表证的典型表现。\\n\\n3. **寒证**虽然也是有可能的因素，但由于症状中的“增厚”症状并不直接指向明显的寒象，因此相对较少考虑。\\n\\n综上所述，根据中医理论，这名患儿的症状应被诊断为“表证”，而不是单纯的“风热伤表”。这一诊断基于症状的表征特点及其在湿热环境和慢性炎症背景下的可能性。<|endoftext|>', '首先，我们需要搞清楚胸水中可能存在的成分。胸水可以是液体、浆细胞或者纤维细胞，这会影响我们后续的诊断。\\n\\n那么，哪种实验室检查能够给我们最直接的信息呢？\\n\\n血常规是个好开始，可以帮助我们看看血液里的生化指标，但主要还是看整体健康状态。\\n\\n哦，对了，胸膜活检！这是个关键步骤。通过胸膜活检得到胸水的具体成分和来源，这能告诉我们胸水中有什么物质在作怪。\\n\\n当然，CT扫描也是个不可少的工具。它不仅能帮助确认胸水的位置，还能给我们提供一个直观的影像学视角。\\n\\n不过，为了知道胸水到底是什么性质的，胸膜活检应该是更直接的选择。\\n\\n但是，等一下，我们只需要确定胸水的性质，也许不需要那么复杂的检查。\\n\\n如果胸水中的蛋白含量高，那很可能就是蛋白胸水，这种情况通常伴随着感染或肿瘤。\\n\\n如果是脂质性胸水，那很可能是脂肪沉积，这种情况下可能与慢性病、炎症有关。\\n\\n至于纤维性胸水，往往和坏血病有关。\\n\\n所以，我们可以通过胸膜活检来测定蛋白水平，从而判断是哪种类型的胸水量。\\n\\n这样看来，胸膜活检确实是最直接有效的手段。\\n\\n综上所述，胸膜活检是一个值得信赖的初步检查方法，能帮我们更好地了解患者的胸水量性质。\\n### 答案：针对这名60岁的男性患者，他的情况涉及肺结核伴右侧胸腔积液的诊断。要明确胸水的具体性质，胸膜活检是最直接且必要的检查方法。通过胸膜活检，我们可以准确测定胸水中的蛋白质含量，从而判断是否存在蛋白胸水，这通常与感染或肿瘤相关；或者测定脂质含量以判断为脂质性胸水，常与慢性病、炎症有关；或者观察纤维性胸水是否由坏血病引起。因此，在这个案例中，胸膜活检是了解胸水性质的最佳实验室检查。<|endoftext|>']\n",
      "refs answer: \n",
      " ['从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。', '对于已经诊断为肺结核伴右侧胸腔积液的患者，为了更好地了解胸水的性质，可以通过检测胸水中的腺苷脱氨酶（ADA）活性来提供有价值的线索。ADA活性高通常提示结核性胸腔积液的可能性更大，因此在这种情况下，ADA检测相较于其他指标如蛋白质和乳酸脱氢酶（LDH）而言，更具诊断意义。']\n"
     ]
    }
   ],
   "source": [
    "print(\"base answer: \\n\", base_answers[:2])\n",
    "print(\"lora answer: \\n\", lora_answers[:2])\n",
    "print(\"refs answer: \\n\", ref_answers[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing two responses ...\n",
      "BERTScore | 原始模型: 0.765981 | LoRA模型: 0.770343\n"
     ]
    }
   ],
   "source": [
    "# 计算BERTScore\n",
    "print(\"Comparing two responses ...\")\n",
    "# 定义一个函数来截断过长的文本\n",
    "def truncate_texts(texts, max_length=512):\n",
    "    \"\"\"截断文本到指定的最大字符长度\"\"\"\n",
    "    return [text[:max_length] for text in texts]\n",
    "\n",
    "# 截断文本以避免超出BERT模型的最大长度限制\n",
    "truncated_base_answers = truncate_texts(base_answers)\n",
    "truncated_lora_answers = truncate_texts(lora_answers)\n",
    "truncated_ref_answers = truncate_texts(ref_answers)\n",
    "\n",
    "# 使用截断后的文本计算BERTScore\n",
    "_, _, base_bert = score(truncated_base_answers, truncated_ref_answers, \n",
    "                        lang=\"zh\", \n",
    "                        model_type=bert_model_path, \n",
    "                        num_layers=12, \n",
    "                        device=\"cuda\")\n",
    "\n",
    "_, _, lora_bert = score(truncated_lora_answers, truncated_ref_answers, \n",
    "                        lang=\"zh\", \n",
    "                        model_type=bert_model_path, \n",
    "                        num_layers=12, \n",
    "                        device=\"cuda\")\n",
    "\n",
    "print(f\"BERTScore | 原始模型: {base_bert.mean().item():.6f} | LoRA模型: {lora_bert.mean().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.262 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE评分结果:\n",
      "原始模型 | ROUGE-1: 0.314, ROUGE-2: 0.108, ROUGE-L: 0.158\n",
      "LoRA模型 | ROUGE-1: 0.321, ROUGE-2: 0.109, ROUGE-L: 0.163\n"
     ]
    }
   ],
   "source": [
    "# 使用其他评估指标作为替代\n",
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "\n",
    "# 计算ROUGE分数\n",
    "def calculate_rouge(hyps, refs):\n",
    "    rouge = Rouge()\n",
    "    scores = []\n",
    "    for hyp, ref in zip(hyps, refs):\n",
    "        hyp = ' '.join(jieba.cut(hyp))\n",
    "        ref = ' '.join(jieba.cut(ref))\n",
    "        score = rouge.get_scores(hyp, ref)[0]\n",
    "        scores.append(score)\n",
    "    \n",
    "    # 计算平均分数\n",
    "    avg_scores = {\n",
    "        'rouge-1': sum(s['rouge-1']['f'] for s in scores) / len(scores),\n",
    "        'rouge-2': sum(s['rouge-2']['f'] for s in scores) / len(scores),\n",
    "        'rouge-l': sum(s['rouge-l']['f'] for s in scores) / len(scores)\n",
    "    }\n",
    "    return avg_scores\n",
    "\n",
    "# 计算基础模型和LoRA模型的ROUGE分数\n",
    "base_rouge = calculate_rouge(base_answers, ref_answers)\n",
    "lora_rouge = calculate_rouge(lora_answers, ref_answers)\n",
    "\n",
    "print(\"ROUGE评分结果:\")\n",
    "print(f\"原始模型 | ROUGE-1: {base_rouge['rouge-1']:.3f}, ROUGE-2: {base_rouge['rouge-2']:.3f}, ROUGE-L: {base_rouge['rouge-l']:.3f}\")\n",
    "print(f\"LoRA模型 | ROUGE-1: {lora_rouge['rouge-1']:.3f}, ROUGE-2: {lora_rouge['rouge-2']:.3f}, ROUGE-L: {lora_rouge['rouge-l']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
