{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 23:54:17.089143: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-03 23:54:17.225708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741017257.278601   68086 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741017257.293585   68086 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-03 23:54:17.428365: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import os\n",
    "import json\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "# 设置可见GPU设备（根据实际GPU情况调整）\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 指定仅使用GPU \n",
    "\n",
    "# 路径配置 ------------------------------------------------------------------------\n",
    "base_model_path = \"/home/jzyoung/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B\" # 原始预训练模型路径\n",
    "peft_model_path = \"./output/\" # LoRA微调后保存的适配器路径\n",
    "bert_model_path=\"/home/jzyoung/.cache/modelscope/hub/models/tiansz/bert-base-chinese\"\n",
    "\n",
    "# 模型加载 ------------------------------------------------------------------------\n",
    "# 初始化分词器（使用与训练时相同的tokenizer）\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# 加载基础模型（半精度加载节省显存）\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "  base_model_path,\n",
    "  torch_dtype=torch.float16, # 使用float16精度\n",
    "  device_map=\"auto\"      # 自动分配设备（CPU/GPU）\n",
    ")\n",
    "\n",
    "# 加载LoRA适配器（在基础模型上加载微调参数）\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "  base_model, \n",
    "  peft_model_path,\n",
    "  torch_dtype=torch.float16,\n",
    "  device_map=\"auto\"\n",
    ")\n",
    "# 合并LoRA权重到基础模型（提升推理速度，但会失去再次训练的能力）\n",
    "lora_model = lora_model.merge_and_unload() \n",
    "lora_model.eval() # 设置为评估模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 生成函数 ------------------------------------------------------------------------\n",
    "def generate_response(model, prompt):\n",
    "  \"\"\"统一的生成函数\n",
    "  参数：\n",
    "    model : 要使用的模型实例\n",
    "    prompt : 符合格式要求的输入文本\n",
    "  返回：\n",
    "    清洗后的回答文本\n",
    "  \"\"\"\n",
    "  # 输入编码（保持与训练时相同的处理方式）\n",
    "  inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",     # 返回PyTorch张量\n",
    "    max_length=1024,        # 最大输入长度（与训练时一致）\n",
    "    truncation=True,       # 启用截断\n",
    "    padding=\"max_length\"     # 填充到最大长度（保证batch一致性）\n",
    "  ).to(model.device)        # 确保输入与模型在同一设备\n",
    "\n",
    "  # 文本生成（关闭梯度计算以节省内存）\n",
    "  with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "      input_ids=inputs.input_ids,\n",
    "      attention_mask=inputs.attention_mask,\n",
    "      max_new_tokens=1024,    # 生成内容的最大token数（控制回答长度）\n",
    "      temperature=0.7,     # 温度参数（0.0-1.0，值越大随机性越强）\n",
    "      top_p=0.9,        # 核采样参数（保留累积概率前90%的token）\n",
    "      repetition_penalty=1.1, # 重复惩罚系数（>1.0时抑制重复内容）\n",
    "      eos_token_id=tokenizer.eos_token_id, # 结束符ID\n",
    "      pad_token_id=tokenizer.pad_token_id, # 填充符ID \n",
    "    )\n",
    "  \n",
    "  # 解码与清洗输出\n",
    "  full_text = tokenizer.decode(outputs[0], skip_special_tokens=True) # 跳过特殊token\n",
    "  answer = full_text.split(\"### 答案：\\n\")[-1].strip() # 提取答案部分\n",
    "  return answer\n",
    "\n",
    "# 对比测试函数 --------------------------------------------------------------------\n",
    "def compare_models(question):\n",
    "  \"\"\"模型对比函数\n",
    "  参数：\n",
    "    question : 自然语言形式的医疗问题\n",
    "  \"\"\"\n",
    "  # 构建符合训练格式的prompt（注意与训练时格式完全一致）\n",
    "  prompt = f\"诊断问题：{question}\\n详细分析：\\n### 答案：\\n\"\n",
    "  \n",
    "  # 双模型生成\n",
    "  base_answer = generate_response(base_model, prompt) # 原始模型\n",
    "  lora_answer = generate_response(lora_model, prompt) # 微调模型\n",
    "  \n",
    "  # 终端彩色打印对比结果\n",
    "  print(\"\\n\" + \"=\"*50) # 分隔线\n",
    "  print(f\"问题：{question}\")\n",
    "  print(\"-\"*50)\n",
    "  print(f\"\\033[1;34m[原始模型]\\033[0m\\n{base_answer}\") # 蓝色显示原始模型结果\n",
    "  print(\"-\"*50)\n",
    "  print(f\"\\033[1;32m[LoRA模型]\\033[0m\\n{lora_answer}\") # 绿色显示微调模型结果\n",
    "  print(\"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file:  [{'Question': '根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？', 'Complex_CoT': '这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\\n\\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\\n\\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\\n\\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\\n\\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\\n\\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\\n\\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\\n\\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\\n\\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\\n\\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。', 'Response': '从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。'}, {'Question': '对于一名60岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，请问哪一项实验室检查对了解胸水的性质更有帮助？', 'Complex_CoT': \"嗯，有一个60岁的男性患者，出现了右侧胸疼，而且X光显示右侧肋膈角消失，这看起来很像是胸腔积液的问题。医生诊断是肺结核伴右侧胸腔积液。那我们就得想想，什么样的实验室检查能帮助我们更好地理解这个胸水的性质呢？\\n\\n首先，我们得从基础知识说起。胸腔积液就是说胸腔里有了多余的液体。这液体的来源可能是感染、恶性肿瘤或者其他因素。病因有些复杂，所以了解胸水性质很关键。\\n\\n嗯，实验室检查一般是用来分析胸水的，看看它到底是从哪儿来的。常见的检测项包括蛋白质、乳酸脱氢酶（LDH）、葡萄糖，以及更具体的病原检测，比如结核菌。\\n\\n患者是肺结核，那我们就要考虑到这可能是结核性胸腔积液。先要判断胸水的类型：是漏出液还是渗出液呢？为了确定这个，我们通常会用Light's标准，这个标准可以通过胸水的蛋白浓度和LDH水平区分。\\n\\n但是吧，光知道是渗出液可能还不足以确认是不是结核引起的。这时，结核相关的精确检测就显得格外重要，比如说结核菌PCR或者ADA（腺苷脱氨酶）活性。\\n\\n对了，ADA这个指标很有意思，特别是在结核性胸腔积液中。当ADA活性高的时候，通常会提示我们大概率是结核病。因此，虽然蛋白质和LDH很重要，但要确认结核，ADA或许更直接些。\\n\\n也就是说，虽然最开始我们要确认胸水是渗出液，但结合患者肺结核的情况，ADA检测会给我们更好的线索。\\n\\n所以，经过这么一番思考，我觉得对于已经被诊断为肺结核的患者来说，检测腺苷脱氨酶（ADA）更有指引性。这能帮忙进一步确认胸水与结核感染的关联。\\n\\n嗯，综上所述，ADA作为分析结核性胸腔积液的指标真的非常有效，最终还是选择它来作进一步检查。\", 'Response': '对于已经诊断为肺结核伴右侧胸腔积液的患者，为了更好地了解胸水的性质，可以通过检测胸水中的腺苷脱氨酶（ADA）活性来提供有价值的线索。ADA活性高通常提示结核性胸腔积液的可能性更大，因此在这种情况下，ADA检测相较于其他指标如蛋白质和乳酸脱氢酶（LDH）而言，更具诊断意义。'}]\n",
      "Generating reponses of base model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:18<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating reponses of lora sft model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:48<00:00,  8.17s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"./dataset/medical_o1_sft_Chinese.json\") as f:\n",
    "    test_data = json.load(f) \n",
    "    print(\"load file: \", test_data[:2])\n",
    "\n",
    "# 数据量比较大，我们只选择50条数据进行测试\n",
    "test_data=test_data[:50]\n",
    "# 批量生成回答\n",
    "\n",
    "def batch_generate(model, questions):\n",
    "    answers = []\n",
    "    for q in tqdm(questions):\n",
    "        prompt = f\"诊断问题：{q}\\n详细分析：\\n### 答案：\\n\"\n",
    "        ans = generate_response(model, prompt)\n",
    "        answers.append(ans)\n",
    "    return answers\n",
    "\n",
    "# 生成结果\n",
    "print(\"Generating reponses of base model ...\")\n",
    "base_answers = batch_generate(base_model, [d[\"Question\"] for d in test_data])\n",
    "print(\"Generating reponses of lora sft model ...\")\n",
    "lora_answers = batch_generate(lora_model, [d[\"Question\"] for d in test_data])\n",
    "ref_answers = [d[\"Response\"] for d in test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base answer: \n",
      " ['这个小孩的情况很典型啊。他的症状包括头皮上的结节、皮肤增厚，以及在炎热天气时特别容易出疹。这些都提示我们可能是在考虑热症。而且，他一直都不愈合，说明这不是简单的风寒或者湿气的问题。\\n\\n仔细想想，夏天的高温会刺激皮肤和黏膜，让结节更容易形成，而这些结节又常常是由于感染引起的。这让我想到热症，因为这个季节容易引发细菌感染，比如金黄色葡萄球菌。\\n\\n结合这些特点，我觉得最有可能的是热症。因为这种情况下，皮肤容易受到感染，而且没有解决的办法，说明病情已经进展到严重阶段。再加上他现在的情况，像 AAC（急性间歇性皮炎）或ICP（间歇性皮炎），也符合这个描述。\\n\\n哦，还有，这个孩子的症状确实很符合热症的表现。在夏季，他的身体很容易受到高温的影响，导致感染。因此，在中医诊断上，这种情况应该是热症。\\n\\n### 答案：根据描述，这名小朋友的症状与夏季感染相关，尤其是与热症相符。在中医诊断中，热症通常由高温引起的感染所引起，例如金黄色葡萄球菌感染等。该患儿在夏季出现头皮上的多处小结节，并长期未愈合，同时伴随皮肤增厚和口不收敛等症状，这些都指向了感染的可能性。\\n\\n此外，他现在的情况还出现了溃破流脓，说明炎症已经发展为脓性感染。而这些症状与ICP（间歇性皮炎）或AAC（急性间歇性皮炎）较为一致。因此，综合考虑这些信息，该病例最可能的中医诊断是热症。\\n\\n总结来说，这名小朋友的情况符合热症的临床表现，特别是由于夏季高温和感染因素引起的皮炎。建议尽快进行相应的医学评估和治疗以改善症状。<|endoftext|>', '对于这名60岁的男性患者，他的胸痛和X线结果显示右侧肋膈角消失以及肺结核伴右侧胸腔积液。这些症状通常提示有胸腔积液的存在。为了更好地了解胸水的性质，我们需要进行一些必要的检测。\\n\\n首先，胸水性质的判定需要通过胸部CT来确认。这可以提供关于胸腔内液体状态、量度和形态的信息。然而，若仅凭影像学检查是不够的，因为还需要知道是否有结节或者病变存在。\\n\\n对于确定性了解胸水的类型（如是血性还是非血性的），通常情况下，需要进行组织活检以获得样本。这可以帮助我们识别出血液或非血液成分，并进一步判断胸水的性质。\\n\\n因此，在这个具体的情况下，组织活检可能是一个更为直接且准确的方法来了解胸水的性质。此外，胸水的培养结果也是一个重要的指标，但通常与细胞学检查相关，而不是直接的胸水性质鉴定。\\n\\n综上所述，对于该患者来说，最能帮助明确胸水性质的实验室检查是组织活检。\\n|  |  |\\n|---|---|\\n对于这名60岁男性患者的情况，为了清楚地了解胸水的性质，组织活检是最有效的检查方法。组织活检可以直接获取胸水的样本，从而帮助我们确定胸水是血液的还是非血液的。这对于临床决策至关重要。<|endoftext|>']\n",
      "lora answer: \n",
      " ['这个小孩的情况有点复杂。首先，考虑到他在夏季头皮上出现了多个小结节，并且这些结节持续不愈合。这种情况让我想到可能跟热有关，因为在夏季，身体的内热容易引发类似情况。\\n\\n接着，我发现这个小孩的皮肤正在长得很厚，而且已经有空洞了。这样的症状让我考虑的是感染，特别是湿热性感染的可能性。湿热不仅会导致皮肤变厚，还会引起脓点和溃疡。\\n\\n此外，他还出现了流脓的情况。这进一步支持了我们对湿热性的怀疑，因为湿热常常会引起这种脓点现象。不过，我得再想一想，湿热是不是也有可能是其他类型的感染呢？比如，气虚型湿热性皮炎。但通常情况下，像这种有空洞、皮肤厚的地方，还是偏向于湿热性。\\n\\n还有一个细节值得关注，就是他口也不收敛。这一点让我想到了胃的包块问题。通常情况下，这种包块可能会伴随一些其他症状，比如发热、脉搏加快或面色苍白等，但是，我需要确认是否与这个小孩的症状相关。\\n\\n结合所有信息来看，夏发结节加上皮肤 thick and holes plus loquit flow, 肺部包块的表现，似乎都在指向湿热性皮炎。这种病通常是因为体内湿热导致的，特别是在夏季。所以，综合来看，这位小孩的情况很可能是湿热性皮炎。\\n\\n不过，我觉得最好还是通过专业医生的帮助进行更详细的检查，以确保没有漏掉任何潜在的危险因素。毕竟，医学诊断总是需要专业的评估和验证。因此，建议尽快找医生做进一步的诊断和治疗，帮助孩子更好地康复。\\\\n### 答案：根据您提供的描述，这名1岁小孩的症状与湿热性皮炎非常吻合。湿热性皮炎通常表现为热象明显的结节，例如夏发结节，以及皮肤增厚和空洞，同时伴有脓点和溃疡。此外，口不收敛的问题也可以解释为包块，虽然包块通常伴随着其他症状如发热、脉搏快或面色苍白，但在某些情况下也可能与湿热性皮炎相关联。综上所述，您描述的情景很可能属于湿热性皮炎。建议尽快就医进行确诊及相应的治疗。<|endoftext|>', '在考虑胸水性质时，我们需要了解其中可能存在的成分。首先，胸水通常由蛋白质、脂肪和脂质组成，但具体成分是通过血清和胸水样品进行检测来确认的。因此，血清蛋白定量测定可以为我们提供一些线索。\\n\\n此外，在胸水性质评估中，CT扫描可以帮助我们理解胸膜内的液体结构。虽然CT没有直接给出成分的具体信息，但它可以给我们一个整体的胸膜结构参考，这对于我们进一步的病理分析很有用。\\n\\n当然，如果需要更具体的成分信息，比如脂肪含量或乳酸酸中毒标志，实验室检查就变得很重要了。通过组织穿刺，我们可以获取胸水中的脂肪比例，这对判断其成分特性有重要帮助。\\n\\n当然，我们也可以通过血清和胸水样品的化学分析（如色谱分析）来确定胸水的成分。这对于了解胸水的性质是一个很好的方法。\\n\\n总结来说，对于了解胸水的性质，血清蛋白定量和组织穿刺都是必要的。然而，CT扫描在理解胸膜结构方面确实具有帮助作用。\\n\\n### 答案：要评估胸水的性质，除了使用血清蛋白定量，还需要通过组织穿刺来获得胸水样品，以便于进一步的分析。血清蛋白定量可以帮助我们初步了解胸水中的蛋白质成分。而CT扫描则提供了关于胸膜内部液体分布的信息，有助于更好地理解胸膜结构，这在后续的病理分析中可能会起到辅助作用。\\n\\n总之，对于了解胸水的性质，血清蛋白定量以及组织穿刺是必要且有价值的检查。']\n",
      "refs answer: \n",
      " ['从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。', '对于已经诊断为肺结核伴右侧胸腔积液的患者，为了更好地了解胸水的性质，可以通过检测胸水中的腺苷脱氨酶（ADA）活性来提供有价值的线索。ADA活性高通常提示结核性胸腔积液的可能性更大，因此在这种情况下，ADA检测相较于其他指标如蛋白质和乳酸脱氢酶（LDH）而言，更具诊断意义。']\n"
     ]
    }
   ],
   "source": [
    "print(\"base answer: \\n\", base_answers[:2])\n",
    "print(\"lora answer: \\n\", lora_answers[:2])\n",
    "print(\"refs answer: \\n\", ref_answers[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing two responses ...\n",
      "BERTScore | 原始模型: 0.775925 | LoRA模型: 0.773626\n"
     ]
    }
   ],
   "source": [
    "# 计算BERTScore\n",
    "print(\"Comparing two responses ...\")\n",
    "# 定义一个函数来截断过长的文本\n",
    "def truncate_texts(texts, max_length=512):\n",
    "    \"\"\"截断文本到指定的最大字符长度\"\"\"\n",
    "    return [text[:max_length] for text in texts]\n",
    "\n",
    "# 截断文本以避免超出BERT模型的最大长度限制\n",
    "truncated_base_answers = truncate_texts(base_answers)\n",
    "truncated_lora_answers = truncate_texts(lora_answers)\n",
    "truncated_ref_answers = truncate_texts(ref_answers)\n",
    "\n",
    "# 使用截断后的文本计算BERTScore\n",
    "_, _, base_bert = score(truncated_base_answers, truncated_ref_answers, \n",
    "                        lang=\"zh\", \n",
    "                        model_type=bert_model_path, \n",
    "                        num_layers=12, \n",
    "                        device=\"cuda\")\n",
    "\n",
    "_, _, lora_bert = score(truncated_lora_answers, truncated_ref_answers, \n",
    "                        lang=\"zh\", \n",
    "                        model_type=bert_model_path, \n",
    "                        num_layers=12, \n",
    "                        device=\"cuda\")\n",
    "\n",
    "print(f\"BERTScore | 原始模型: {base_bert.mean().item():.6f} | LoRA模型: {lora_bert.mean().item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.254 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE评分结果:\n",
      "原始模型 | ROUGE-1: 0.319, ROUGE-2: 0.105, ROUGE-L: 0.172\n",
      "LoRA模型 | ROUGE-1: 0.326, ROUGE-2: 0.105, ROUGE-L: 0.183\n"
     ]
    }
   ],
   "source": [
    "# 使用其他评估指标作为替代\n",
    "from rouge_chinese import Rouge\n",
    "import jieba\n",
    "\n",
    "# 计算ROUGE分数\n",
    "def calculate_rouge(hyps, refs):\n",
    "    rouge = Rouge()\n",
    "    scores = []\n",
    "    for hyp, ref in zip(hyps, refs):\n",
    "        hyp = ' '.join(jieba.cut(hyp))\n",
    "        ref = ' '.join(jieba.cut(ref))\n",
    "        score = rouge.get_scores(hyp, ref)[0]\n",
    "        scores.append(score)\n",
    "    \n",
    "    # 计算平均分数\n",
    "    avg_scores = {\n",
    "        'rouge-1': sum(s['rouge-1']['f'] for s in scores) / len(scores),\n",
    "        'rouge-2': sum(s['rouge-2']['f'] for s in scores) / len(scores),\n",
    "        'rouge-l': sum(s['rouge-l']['f'] for s in scores) / len(scores)\n",
    "    }\n",
    "    return avg_scores\n",
    "\n",
    "# 计算基础模型和LoRA模型的ROUGE分数\n",
    "base_rouge = calculate_rouge(base_answers, ref_answers)\n",
    "lora_rouge = calculate_rouge(lora_answers, ref_answers)\n",
    "\n",
    "print(\"ROUGE评分结果:\")\n",
    "print(f\"原始模型 | ROUGE-1: {base_rouge['rouge-1']:.3f}, ROUGE-2: {base_rouge['rouge-2']:.3f}, ROUGE-L: {base_rouge['rouge-l']:.3f}\")\n",
    "print(f\"LoRA模型 | ROUGE-1: {lora_rouge['rouge-1']:.3f}, ROUGE-2: {lora_rouge['rouge-2']:.3f}, ROUGE-L: {lora_rouge['rouge-l']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
