{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file:  [{'Question': '根据描述，一个1岁的孩子在夏季头皮出现多处小结节，长期不愈合，且现在疮大如梅，溃破流脓，口不收敛，头皮下有空洞，患处皮肤增厚。这种病症在中医中诊断为什么病？', 'Complex_CoT': '这个小孩子在夏天头皮上长了些小结节，一直都没好，后来变成了脓包，流了好多脓。想想夏天那么热，可能和湿热有关。才一岁的小孩，免疫力本来就不强，夏天的湿热没准就侵袭了身体。\\n\\n用中医的角度来看，出现小结节、再加上长期不愈合，这些症状让我想到了头疮。小孩子最容易得这些皮肤病，主要因为湿热在体表郁结。\\n\\n但再看看，头皮下还有空洞，这可能不止是简单的头疮。看起来病情挺严重的，也许是脓肿没治好。这样的情况中医中有时候叫做禿疮或者湿疮，也可能是另一种情况。\\n\\n等一下，头皮上的空洞和皮肤增厚更像是疾病已经深入到头皮下，这是不是说明有可能是流注或瘰疬？这些名字常描述头部或颈部的严重感染，特别是有化脓不愈合，又形成通道或空洞的情况。\\n\\n仔细想想，我怎么感觉这些症状更贴近瘰疬的表现？尤其考虑到孩子的年纪和夏天发生的季节性因素，湿热可能是主因，但可能也有火毒或者痰湿造成的滞留。\\n\\n回到基本的症状描述上看，这种长期不愈合又复杂的状况，如果结合中医更偏重的病名，是不是有可能是涉及更深层次的感染？\\n\\n再考虑一下，这应该不是单纯的瘰疬，得仔细分析头皮增厚并出现空洞这样的严重症状。中医里头，这样的表现可能更符合‘蚀疮’或‘头疽’。这些病名通常描述头部严重感染后的溃烂和组织坏死。\\n\\n看看季节和孩子的体质，夏天又湿又热，外邪很容易侵入头部，对孩子这么弱的免疫系统简直就是挑战。头疽这个病名听起来真是切合，因为它描述的感染严重，溃烂到出现空洞。\\n\\n不过，仔细琢磨后发现，还有个病名似乎更为合适，叫做‘蝼蛄疖’，这病在中医里专指像这种严重感染并伴有深部空洞的情况。它也涵盖了化脓和皮肤增厚这些症状。\\n\\n哦，该不会是夏季湿热，导致湿毒入侵，孩子的体质不能御，其病情发展成这样的感染？综合分析后我觉得‘蝼蛄疖’这个病名真是相当符合。', 'Response': '从中医的角度来看，你所描述的症状符合“蝼蛄疖”的病症。这种病症通常发生在头皮，表现为多处结节，溃破流脓，形成空洞，患处皮肤增厚且长期不愈合。湿热较重的夏季更容易导致这种病症的发展，特别是在免疫力较弱的儿童身上。建议结合中医的清热解毒、祛湿消肿的治疗方法进行处理，并配合专业的医疗建议进行详细诊断和治疗。'}, {'Question': '对于一名60岁男性患者，出现右侧胸疼并在X线检查中显示右侧肋膈角消失，诊断为肺结核伴右侧胸腔积液，请问哪一项实验室检查对了解胸水的性质更有帮助？', 'Complex_CoT': \"嗯，有一个60岁的男性患者，出现了右侧胸疼，而且X光显示右侧肋膈角消失，这看起来很像是胸腔积液的问题。医生诊断是肺结核伴右侧胸腔积液。那我们就得想想，什么样的实验室检查能帮助我们更好地理解这个胸水的性质呢？\\n\\n首先，我们得从基础知识说起。胸腔积液就是说胸腔里有了多余的液体。这液体的来源可能是感染、恶性肿瘤或者其他因素。病因有些复杂，所以了解胸水性质很关键。\\n\\n嗯，实验室检查一般是用来分析胸水的，看看它到底是从哪儿来的。常见的检测项包括蛋白质、乳酸脱氢酶（LDH）、葡萄糖，以及更具体的病原检测，比如结核菌。\\n\\n患者是肺结核，那我们就要考虑到这可能是结核性胸腔积液。先要判断胸水的类型：是漏出液还是渗出液呢？为了确定这个，我们通常会用Light's标准，这个标准可以通过胸水的蛋白浓度和LDH水平区分。\\n\\n但是吧，光知道是渗出液可能还不足以确认是不是结核引起的。这时，结核相关的精确检测就显得格外重要，比如说结核菌PCR或者ADA（腺苷脱氨酶）活性。\\n\\n对了，ADA这个指标很有意思，特别是在结核性胸腔积液中。当ADA活性高的时候，通常会提示我们大概率是结核病。因此，虽然蛋白质和LDH很重要，但要确认结核，ADA或许更直接些。\\n\\n也就是说，虽然最开始我们要确认胸水是渗出液，但结合患者肺结核的情况，ADA检测会给我们更好的线索。\\n\\n所以，经过这么一番思考，我觉得对于已经被诊断为肺结核的患者来说，检测腺苷脱氨酶（ADA）更有指引性。这能帮忙进一步确认胸水与结核感染的关联。\\n\\n嗯，综上所述，ADA作为分析结核性胸腔积液的指标真的非常有效，最终还是选择它来作进一步检查。\", 'Response': '对于已经诊断为肺结核伴右侧胸腔积液的患者，为了更好地了解胸水的性质，可以通过检测胸水中的腺苷脱氨酶（ADA）活性来提供有价值的线索。ADA活性高通常提示结核性胸腔积液的可能性更大，因此在这种情况下，ADA检测相较于其他指标如蛋白质和乳酸脱氢酶（LDH）而言，更具诊断意义。'}]\n",
      "Generating reponses of base model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:22<01:26, 10.80s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import os\n",
    "import json\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "# 设置可见GPU设备（根据实际GPU情况调整）\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 指定仅使用GPU \n",
    "\n",
    "# 路径配置 ------------------------------------------------------------------------\n",
    "base_model_path = \"/home/jzyoung/.cache/modelscope/hub/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-1___5B\" # 原始预训练模型路径\n",
    "peft_model_path = \"./output/\" # LoRA微调后保存的适配器路径\n",
    "\n",
    "# 模型加载 ------------------------------------------------------------------------\n",
    "# 初始化分词器（使用与训练时相同的tokenizer）\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# 加载基础模型（半精度加载节省显存）\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "  base_model_path,\n",
    "  torch_dtype=torch.float16, # 使用float16精度\n",
    "  device_map=\"auto\"      # 自动分配设备（CPU/GPU）\n",
    ")\n",
    "\n",
    "# 加载LoRA适配器（在基础模型上加载微调参数）\n",
    "lora_model = PeftModel.from_pretrained(\n",
    "  base_model, \n",
    "  peft_model_path,\n",
    "  torch_dtype=torch.float16,\n",
    "  device_map=\"auto\"\n",
    ")\n",
    "# 合并LoRA权重到基础模型（提升推理速度，但会失去再次训练的能力）\n",
    "lora_model = lora_model.merge_and_unload() \n",
    "lora_model.eval() # 设置为评估模式\n",
    "\n",
    "# 生成函数 ------------------------------------------------------------------------\n",
    "def generate_response(model, prompt):\n",
    "  \"\"\"统一的生成函数\n",
    "  参数：\n",
    "    model : 要使用的模型实例\n",
    "    prompt : 符合格式要求的输入文本\n",
    "  返回：\n",
    "    清洗后的回答文本\n",
    "  \"\"\"\n",
    "  # 输入编码（保持与训练时相同的处理方式）\n",
    "  inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\",     # 返回PyTorch张量\n",
    "    max_length=1024,        # 最大输入长度（与训练时一致）\n",
    "    truncation=True,       # 启用截断\n",
    "    padding=\"max_length\"     # 填充到最大长度（保证batch一致性）\n",
    "  ).to(model.device)        # 确保输入与模型在同一设备\n",
    "\n",
    "  # 文本生成（关闭梯度计算以节省内存）\n",
    "  with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "      input_ids=inputs.input_ids,\n",
    "      attention_mask=inputs.attention_mask,\n",
    "      max_new_tokens=1024,    # 生成内容的最大token数（控制回答长度）\n",
    "      temperature=0.7,     # 温度参数（0.0-1.0，值越大随机性越强）\n",
    "      top_p=0.9,        # 核采样参数（保留累积概率前90%的token）\n",
    "      repetition_penalty=1.1, # 重复惩罚系数（>1.0时抑制重复内容）\n",
    "      eos_token_id=tokenizer.eos_token_id, # 结束符ID\n",
    "      pad_token_id=tokenizer.pad_token_id, # 填充符ID \n",
    "    )\n",
    "  \n",
    "  # 解码与清洗输出\n",
    "  full_text = tokenizer.decode(outputs[0], skip_special_tokens=True) # 跳过特殊token\n",
    "  answer = full_text.split(\"### 答案：\\n\")[-1].strip() # 提取答案部分\n",
    "  return answer\n",
    "\n",
    "# 对比测试函数 --------------------------------------------------------------------\n",
    "def compare_models(question):\n",
    "  \"\"\"模型对比函数\n",
    "  参数：\n",
    "    question : 自然语言形式的医疗问题\n",
    "  \"\"\"\n",
    "  # 构建符合训练格式的prompt（注意与训练时格式完全一致）\n",
    "  prompt = f\"诊断问题：{question}\\n详细分析：\\n### 答案：\\n\"\n",
    "  \n",
    "  # 双模型生成\n",
    "  base_answer = generate_response(base_model, prompt) # 原始模型\n",
    "  lora_answer = generate_response(lora_model, prompt) # 微调模型\n",
    "  \n",
    "  # 终端彩色打印对比结果\n",
    "  print(\"\\n\" + \"=\"*50) # 分隔线\n",
    "  print(f\"问题：{question}\")\n",
    "  print(\"-\"*50)\n",
    "  print(f\"\\033[1;34m[原始模型]\\033[0m\\n{base_answer}\") # 蓝色显示原始模型结果\n",
    "  print(\"-\"*50)\n",
    "  print(f\"\\033[1;32m[LoRA模型]\\033[0m\\n{lora_answer}\") # 绿色显示微调模型结果\n",
    "  print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "with open(\"./dataset/medical_o1_sft_Chinese.json\") as f:\n",
    "    test_data = json.load(f) \n",
    "    print(\"load file: \", test_data[:2])\n",
    "\n",
    "# 数据量比较大，我们只选择10条数据进行测试\n",
    "test_data=test_data[:10]\n",
    "# 批量生成回答\n",
    "\n",
    "def batch_generate(model, questions):\n",
    "    answers = []\n",
    "    for q in tqdm(questions):\n",
    "        prompt = f\"诊断问题：{q}\\n详细分析：\\n### 答案：\\n\"\n",
    "        ans = generate_response(model, prompt)\n",
    "        answers.append(ans)\n",
    "    return answers\n",
    "\n",
    "# 生成结果\n",
    "print(\"Generating reponses of base model ...\")\n",
    "base_answers = batch_generate(base_model, [d[\"Question\"] for d in test_data])\n",
    "print(\"Generating reponses of lora sft model ...\")\n",
    "lora_answers = batch_generate(lora_model, [d[\"Question\"] for d in test_data])\n",
    "ref_answers = [d[\"Response\"] for d in test_data]\n",
    "\n",
    "bert_model_path=\"xxxxx/model/bert-base-chinese\"\n",
    "# 计算BERTScore\n",
    "print(\"Comparing two responses ...\")\n",
    "_, _, base_bert = score(base_answers, ref_answers, lang=\"zh\",model_type=bert_model_path,num_layers=12,device=\"cuda\")\n",
    "_, _, lora_bert = score(lora_answers, ref_answers, lang=\"zh\",model_type=bert_model_path,num_layers=12,device=\"cuda\")\n",
    "print(f\"BERTScore | 原始模型: {base_bert.mean().item():.3f} | LoRA模型: {lora_bert.mean().item():.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
